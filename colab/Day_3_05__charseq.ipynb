{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Day 3_05._charseq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enoosoft/ai_fsec/blob/master/colab/Day_3_05__charseq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbHvG_DBsrc1"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TBgl-Mvsrc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4689f455-f67b-4422-f95a-ea5bc6aae3e6"
      },
      "source": [
        "# Random seed to make results deterministic and reproducible\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc3d5411a30>"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zrhYoFwsrdB"
      },
      "source": [
        "sample = \" sometimes things \""
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhogKLb_srdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1583c99-4a01-4b4c-e72b-c4934efb0570"
      },
      "source": [
        "# make dictionary\n",
        "char_set = list(set(sample)) # 중복제거\n",
        "char_dic = {c: i for i, c in enumerate(char_set)} # 캐릭터 리스트에 인덱스를 붙임\n",
        "print(char_dic)"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'s': 0, 't': 1, 'e': 2, 'o': 3, 'n': 4, 'm': 5, 'h': 6, ' ': 7, 'g': 8, 'i': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc6UEW4zsrdH"
      },
      "source": [
        "# hyper parameters\n",
        "dic_size = len(char_dic) # one hot encoding size 10개\n",
        "hidden_size = len(char_dic) # 동일하게(default)\n",
        "learning_rate = 0.1"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sEOprXKsrdJ"
      },
      "source": [
        "# data setting. one hot encoding...\n",
        "sample_idx = [char_dic[c] for c in sample]\n",
        "x_data = [sample_idx[:-1]]\n",
        "x_one_hot = [np.eye(dic_size)[x] for x in x_data]\n",
        "y_data = [sample_idx[1:]]"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb-CYtB3Pb9P",
        "outputId": "9ae9e0a0-4be6-4a9c-cd4f-109273e070a5"
      },
      "source": [
        "x_data"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 0, 3, 5, 2, 1, 9, 5, 2, 0, 7, 1, 6, 9, 4, 8, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8xh7NMdPeJp",
        "outputId": "ca946410-bc2b-4e3c-a27f-005fed1c3994"
      },
      "source": [
        "y_data"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 3, 5, 2, 1, 9, 5, 2, 0, 7, 1, 6, 9, 4, 8, 0, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRfM4qPPQS_C",
        "outputId": "452a5783-ec4d-4c8c-aa2f-b3dddd58cf89"
      },
      "source": [
        "x_one_hot"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSYPk7hUsrdL"
      },
      "source": [
        "# transform as torch tensor variable\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQf8_J5I8nbm",
        "outputId": "edae39b3-1315-4c95-ebf5-31d5380cf77a"
      },
      "source": [
        "Y"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 3, 5, 2, 1, 9, 5, 2, 0, 7, 1, 6, 9, 4, 8, 0, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYRv4KNMsrdO"
      },
      "source": [
        "# declare RNN\n",
        "rnn = torch.nn.LSTM(dic_size, hidden_size, batch_first=True)"
      ],
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdcNxUtXsrdQ"
      },
      "source": [
        "# loss & optimizer setting\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), learning_rate)"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rD90R1LMsrdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd27aa6-ffd9-4890-8cfe-103c84a62d6d"
      },
      "source": [
        "# start training\n",
        "for i in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs, _status = rnn(X)\n",
        "    loss = criterion(outputs.view(-1, dic_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    result = outputs.data.numpy().argmax(axis=2)\n",
        "    result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "    # print(i, \"loss: \", loss.item(), \"prediction: \", result, \"true Y: \", y_data, \"prediction str: \", result_str)\n",
        "    print(i, \"loss: \", loss.item(), \"prediction str: \", result_str)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss:  2.3061671257019043 prediction str:  ssstoostossotstos\n",
            "1 loss:  2.2214467525482178 prediction str:  ssmsstsssssttssss\n",
            "2 loss:  2.1490728855133057 prediction str:  ssmtsisssssiiisss\n",
            "3 loss:  2.064013957977295 prediction str:  ssmisiiisstiiiiss\n",
            "4 loss:  1.9420346021652222 prediction str:  smmmtimtsstmimsss\n",
            "5 loss:  1.8224027156829834 prediction str:  smmmtmmts tmmmsss\n",
            "6 loss:  1.6913976669311523 prediction str:  smmmtimes tiimss \n",
            "7 loss:  1.5798211097717285 prediction str:  smmttimes tiiess \n",
            "8 loss:  1.4939411878585815 prediction str:  sometimes tiiess \n",
            "9 loss:  1.4369243383407593 prediction str:  sometimes tiiess \n",
            "10 loss:  1.3901697397232056 prediction str:  sometimes thiess \n",
            "11 loss:  1.3459829092025757 prediction str:  sometimes thiess \n",
            "12 loss:  1.3038923740386963 prediction str:  sometimes things \n",
            "13 loss:  1.2800395488739014 prediction str:  sometimes things \n",
            "14 loss:  1.2556848526000977 prediction str:  sometiees things \n",
            "15 loss:  1.236137866973877 prediction str:  sometiees things \n",
            "16 loss:  1.2186437845230103 prediction str:  sometimes things \n",
            "17 loss:  1.2014367580413818 prediction str:  sometimes things \n",
            "18 loss:  1.1875079870224 prediction str:  sometimes things \n",
            "19 loss:  1.172874927520752 prediction str:  sometimes things \n",
            "20 loss:  1.1615570783615112 prediction str:  sometimes things \n",
            "21 loss:  1.1523523330688477 prediction str:  sometimes things \n",
            "22 loss:  1.1400588750839233 prediction str:  sometimes things \n",
            "23 loss:  1.133603572845459 prediction str:  sometimes things \n",
            "24 loss:  1.1247482299804688 prediction str:  sometimes things \n",
            "25 loss:  1.1174367666244507 prediction str:  sometimes things \n",
            "26 loss:  1.1103081703186035 prediction str:  somttimes things \n",
            "27 loss:  1.107012152671814 prediction str:  somttimes things \n",
            "28 loss:  1.1007107496261597 prediction str:  somttimes things \n",
            "29 loss:  1.0958579778671265 prediction str:  somttimes things \n",
            "30 loss:  1.0926059484481812 prediction str:  somttimes things \n",
            "31 loss:  1.0887815952301025 prediction str:  sometimes things \n",
            "32 loss:  1.0856810808181763 prediction str:  sometimes things \n",
            "33 loss:  1.081600546836853 prediction str:  sometimes things \n",
            "34 loss:  1.0771105289459229 prediction str:  sometimes things \n",
            "35 loss:  1.0734963417053223 prediction str:  sometimes things \n",
            "36 loss:  1.0715941190719604 prediction str:  sometimes things \n",
            "37 loss:  1.0681673288345337 prediction str:  sometimes things \n",
            "38 loss:  1.0667401552200317 prediction str:  sometimes things \n",
            "39 loss:  1.0644850730895996 prediction str:  sometimes things \n",
            "40 loss:  1.0631632804870605 prediction str:  sometimes things \n",
            "41 loss:  1.0613354444503784 prediction str:  sometimes things \n",
            "42 loss:  1.0589500665664673 prediction str:  sometimes things \n",
            "43 loss:  1.0570157766342163 prediction str:  sometimes things \n",
            "44 loss:  1.0547996759414673 prediction str:  sometimes things \n",
            "45 loss:  1.053491234779358 prediction str:  sometimes things \n",
            "46 loss:  1.0515100955963135 prediction str:  sometimes things \n",
            "47 loss:  1.0499292612075806 prediction str:  sometimes things \n",
            "48 loss:  1.048421025276184 prediction str:  sometimes things \n",
            "49 loss:  1.047068476676941 prediction str:  sometimes things \n"
          ]
        }
      ]
    }
  ]
}