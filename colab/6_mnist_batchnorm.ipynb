{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "6_mnist_batchnorm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enoosoft/ai_fsec/blob/master/colab/6_mnist_batchnorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWiJrtF95ARz"
      },
      "source": [
        "# Lab 10 MNIST and softmax\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7lSxHdv5ARz"
      },
      "source": [
        "device = 'cpu' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(1)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Oj65SL5ARz"
      },
      "source": [
        "# parameters\n",
        "learning_rate = 0.01\n",
        "training_epochs = 10\n",
        "batch_size = 32"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0XLMFHA5ARz"
      },
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVRicOiY5ARz"
      },
      "source": [
        "# dataset loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeWEaHQa5ARz"
      },
      "source": [
        "# nn layers 두개의 모델\n",
        "linear1 = torch.nn.Linear(784, 32, bias=True)\n",
        "linear2 = torch.nn.Linear(32, 32, bias=True)\n",
        "linear3 = torch.nn.Linear(32, 10, bias=True)\n",
        "relu = torch.nn.ReLU()\n",
        "bn1 = torch.nn.BatchNorm1d(32)\n",
        "bn2 = torch.nn.BatchNorm1d(32)\n",
        "\n",
        "nn_linear1 = torch.nn.Linear(784, 32, bias=True) \n",
        "nn_linear2 = torch.nn.Linear(32, 32, bias=True)\n",
        "nn_linear3 = torch.nn.Linear(32, 10, bias=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQop17Pk5ARz"
      },
      "source": [
        "# model\n",
        "bn_model = torch.nn.Sequential(linear1, bn1, relu,\n",
        "                            linear2, bn2, relu,\n",
        "                            linear3).to(device) # 배치정규화를 쓴 모델. 노드 > 배치정규화 > 활성화함수, ...\n",
        "nn_model = torch.nn.Sequential(nn_linear1, relu,\n",
        "                               nn_linear2, relu,\n",
        "                               nn_linear3).to(device) # 배치정규화를 안쓴 모델"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyLUpaZF5ARz"
      },
      "source": [
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "bn_optimizer = torch.optim.Adam(bn_model.parameters(), lr=learning_rate)\n",
        "nn_optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pshVvjBt5ARz",
        "outputId": "68227ca4-a599-492f-a400-955818bf3ddc"
      },
      "source": [
        "# Save Losses and Accuracies every epoch\n",
        "# We are going to plot them later\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "\n",
        "train_total_batch = len(train_loader)\n",
        "test_total_batch = len(test_loader)\n",
        "for epoch in range(training_epochs):\n",
        "    bn_model.train()  # set the model to train mode\n",
        "\n",
        "    for X, Y in train_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        bn_optimizer.zero_grad()\n",
        "        bn_prediction = bn_model(X)\n",
        "        bn_loss = criterion(bn_prediction, Y)\n",
        "        bn_loss.backward()\n",
        "        bn_optimizer.step()\n",
        "\n",
        "        nn_optimizer.zero_grad()\n",
        "        nn_prediction = nn_model(X)\n",
        "        nn_loss = criterion(nn_prediction, Y)\n",
        "        nn_loss.backward()\n",
        "        nn_optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        bn_model.eval()     # set the model to evaluation mode\n",
        "\n",
        "        # Test the model using train sets\n",
        "        bn_loss, nn_loss, bn_acc, nn_acc = 0, 0, 0, 0\n",
        "        for i, (X, Y) in enumerate(train_loader):\n",
        "            X = X.view(-1, 28 * 28).to(device)\n",
        "            Y = Y.to(device)\n",
        "\n",
        "            bn_prediction = bn_model(X)\n",
        "            bn_correct_prediction = torch.argmax(bn_prediction, 1) == Y\n",
        "            bn_loss += criterion(bn_prediction, Y)\n",
        "            bn_acc += bn_correct_prediction.float().mean()\n",
        "\n",
        "            nn_prediction = nn_model(X)\n",
        "            nn_correct_prediction = torch.argmax(nn_prediction, 1) == Y\n",
        "            nn_loss += criterion(nn_prediction, Y)\n",
        "            nn_acc += nn_correct_prediction.float().mean()\n",
        "\n",
        "        bn_loss, nn_loss, bn_acc, nn_acc = bn_loss / train_total_batch, nn_loss / train_total_batch, bn_acc / train_total_batch, nn_acc / train_total_batch\n",
        "\n",
        "        # Save train losses/acc\n",
        "        train_losses.append([bn_loss, nn_loss])\n",
        "        train_accs.append([bn_acc, nn_acc])\n",
        "        print(\n",
        "            '[Epoch %d-TRAIN] Batchnorm Loss(Acc): bn_loss:%.5f(bn_acc:%.2f) vs No Batchnorm Loss(Acc): nn_loss:%.5f(nn_acc:%.2f)' % (\n",
        "            (epoch + 1), bn_loss.item(), bn_acc.item(), nn_loss.item(), nn_acc.item()))\n",
        "        # Test the model using test sets\n",
        "        bn_loss, nn_loss, bn_acc, nn_acc = 0, 0, 0, 0\n",
        "        for i, (X, Y) in enumerate(test_loader):\n",
        "            X = X.view(-1, 28 * 28).to(device)\n",
        "            Y = Y.to(device)\n",
        "\n",
        "            bn_prediction = bn_model(X)\n",
        "            bn_correct_prediction = torch.argmax(bn_prediction, 1) == Y\n",
        "            bn_loss += criterion(bn_prediction, Y)\n",
        "            bn_acc += bn_correct_prediction.float().mean()\n",
        "\n",
        "            nn_prediction = nn_model(X)\n",
        "            nn_correct_prediction = torch.argmax(nn_prediction, 1) == Y\n",
        "            nn_loss += criterion(nn_prediction, Y)\n",
        "            nn_acc += nn_correct_prediction.float().mean()\n",
        "\n",
        "        bn_loss, nn_loss, bn_acc, nn_acc = bn_loss / test_total_batch, nn_loss / test_total_batch, bn_acc / test_total_batch, nn_acc / test_total_batch\n",
        "\n",
        "        # Save valid losses/acc\n",
        "        valid_losses.append([bn_loss, nn_loss])\n",
        "        valid_accs.append([bn_acc, nn_acc])\n",
        "        print(\n",
        "            '[Epoch %d-VALID] Batchnorm Loss(Acc): bn_loss:%.5f(bn_acc:%.2f) vs No Batchnorm Loss(Acc): nn_loss:%.5f(nn_acc:%.2f)' % (\n",
        "                (epoch + 1), bn_loss.item(), bn_acc.item(), nn_loss.item(), nn_acc.item()))\n",
        "        print()\n",
        "\n",
        "print('Learning finished') # 배치정규화를 한 모델이 정확도가 높다. train set은 정확도가 높아지나 valid set 은 정확도가 증가하지 않는다. "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1-TRAIN] Batchnorm Loss(Acc): bn_loss:0.04206(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.13347(nn_acc:0.96)\n",
            "[Epoch 1-VALID] Batchnorm Loss(Acc): bn_loss:0.08622(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.22947(nn_acc:0.95)\n",
            "\n",
            "[Epoch 2-TRAIN] Batchnorm Loss(Acc): bn_loss:0.04053(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.11363(nn_acc:0.97)\n",
            "[Epoch 2-VALID] Batchnorm Loss(Acc): bn_loss:0.09219(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.19865(nn_acc:0.96)\n",
            "\n",
            "[Epoch 3-TRAIN] Batchnorm Loss(Acc): bn_loss:0.03703(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.10418(nn_acc:0.97)\n",
            "[Epoch 3-VALID] Batchnorm Loss(Acc): bn_loss:0.08170(bn_acc:0.98) vs No Batchnorm Loss(Acc): nn_loss:0.19229(nn_acc:0.96)\n",
            "\n",
            "[Epoch 4-TRAIN] Batchnorm Loss(Acc): bn_loss:0.03786(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.10665(nn_acc:0.97)\n",
            "[Epoch 4-VALID] Batchnorm Loss(Acc): bn_loss:0.08776(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.20404(nn_acc:0.96)\n",
            "\n",
            "[Epoch 5-TRAIN] Batchnorm Loss(Acc): bn_loss:0.04006(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.14932(nn_acc:0.96)\n",
            "[Epoch 5-VALID] Batchnorm Loss(Acc): bn_loss:0.09294(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.25799(nn_acc:0.95)\n",
            "\n",
            "[Epoch 6-TRAIN] Batchnorm Loss(Acc): bn_loss:0.03447(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.10894(nn_acc:0.97)\n",
            "[Epoch 6-VALID] Batchnorm Loss(Acc): bn_loss:0.08269(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.22616(nn_acc:0.96)\n",
            "\n",
            "[Epoch 7-TRAIN] Batchnorm Loss(Acc): bn_loss:0.03393(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.12506(nn_acc:0.97)\n",
            "[Epoch 7-VALID] Batchnorm Loss(Acc): bn_loss:0.09657(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.21609(nn_acc:0.96)\n",
            "\n",
            "[Epoch 8-TRAIN] Batchnorm Loss(Acc): bn_loss:0.03387(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.11305(nn_acc:0.97)\n",
            "[Epoch 8-VALID] Batchnorm Loss(Acc): bn_loss:0.08845(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.22903(nn_acc:0.96)\n",
            "\n",
            "[Epoch 9-TRAIN] Batchnorm Loss(Acc): bn_loss:0.02963(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.09264(nn_acc:0.97)\n",
            "[Epoch 9-VALID] Batchnorm Loss(Acc): bn_loss:0.09277(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.20551(nn_acc:0.96)\n",
            "\n",
            "[Epoch 10-TRAIN] Batchnorm Loss(Acc): bn_loss:0.03118(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.09743(nn_acc:0.97)\n",
            "[Epoch 10-VALID] Batchnorm Loss(Acc): bn_loss:0.09198(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.20452(nn_acc:0.96)\n",
            "\n",
            "Learning finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqWOnpAd5AR0"
      },
      "source": [
        "def plot_compare(loss_list: list, ylim=None, title=None) -> None:\n",
        "    bn = [i[0] for i in loss_list]\n",
        "    nn = [i[1] for i in loss_list]\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.plot(bn, label='With BN')\n",
        "    plt.plot(nn, label='Without BN')\n",
        "    if ylim:\n",
        "        plt.ylim(ylim)\n",
        "\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid('on')\n",
        "    plt.show()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jboCfjW25AR0",
        "outputId": "2d47a74b-b438-4c6d-95bc-fdcf0938d3f6"
      },
      "source": [
        "plot_compare(train_losses, title='Training Loss at Epoch')\n",
        "plot_compare(train_accs, [0, 1.0], title='Training Acc at Epoch')\n",
        "plot_compare(valid_losses, title='Validation Loss at Epoch')\n",
        "plot_compare(valid_accs, [0, 1.0], title='Validation Acc at Epoch')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1626\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'values'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5b9d67bf9628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss at Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Acc at Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss at Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Acc at Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-227f0860563d>\u001b[0m in \u001b[0;36mplot_compare\u001b[0;34m(loss_list, ylim, title)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'With BN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Without BN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     '''\n\u001b[1;32m   1325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}